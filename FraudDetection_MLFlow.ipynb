{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "------------\n",
        "> â—â—â—âš ï¸  ğŸ’¸   DONT USE GPUâ—â—â—   \n",
        "> **ğŸ§  ğŸ¤‘   USE ONLY CPU (max GB used: RAM 3 - DISC 30)**\n",
        "------------"
      ],
      "metadata": {
        "id": "6ztrbe5ceF_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## IntroducciÃ³n\n",
        "\n",
        "En este proyecto, se implementarÃ¡ un flujo de trabajo integral para la evaluaciÃ³n y selecciÃ³n de modelos de Machine Learning utilizando las herramientas `MLflow` y `pyngrok`. En primer lugar, se instalarÃ¡n las librerÃ­as necesarias y se configurarÃ¡ el entorno de trabajo, aprovechando Google Colab y Google Drive para la gestiÃ³n y almacenamiento de datos. Los datasets de entrenamiento y prueba, junto con los modelos preentrenados y los resultados de los pipelines, se cargarÃ¡n y verificarÃ¡n para asegurar que todos los recursos necesarios estÃ©n disponibles para el anÃ¡lisis.\n",
        "\n",
        "A continuaciÃ³n, se utilizarÃ¡ `ngrok` para establecer un tÃºnel que permitirÃ¡ acceder a la interfaz de usuario de `MLflow` desde una URL pÃºblica. Esto facilitarÃ¡ la visualizaciÃ³n y gestiÃ³n remota de los experimentos de `MLflow`, proporcionando una forma eficiente de monitorear y analizar los resultados de los modelos de Machine Learning. Se iniciarÃ¡ el servidor de `MLflow` y se expondrÃ¡ a travÃ©s de `ngrok`, permitiendo una integraciÃ³n fluida y accesible.\n",
        "\n",
        "Finalmente, se llevarÃ¡ a cabo un proceso sistemÃ¡tico para identificar el mejor modelo entre los evaluados. La funciÃ³n `best_model(results_pipeline)` recorrerÃ¡ los resultados de los modelos almacenados, registrando mÃ©tricas y parÃ¡metros en `MLflow`, y seleccionando el modelo con el mejor rendimiento basado en la precisiÃ³n media y la desviaciÃ³n estÃ¡ndar. Este enfoque garantizarÃ¡ que los resultados sean documentados de manera organizada y accesible, facilitando la selecciÃ³n del modelo mÃ¡s adecuado para futuras implementaciones."
      ],
      "metadata": {
        "id": "zl_cm0cVDWra"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "so7UF4cy6Jqk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44085795-58f6-4ed7-d3e6-36faaa062f93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m25.8/25.8 MB\u001b[0m \u001b[31m56.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m233.0/233.0 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m59.9/59.9 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m107.0/107.0 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m84.4/84.4 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m202.9/202.9 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m52.8/52.8 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m130.5/130.5 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q mlflow pyngrok"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import joblib\n",
        "import subprocess\n",
        "import time\n",
        "import mlflow\n",
        "import sklearn\n",
        "import sklearn.linear_model as lm\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
        "from sklearn.model_selection import cross_val_score, GridSearchCV, StratifiedKFold\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from google.colab import drive\n",
        "from google.colab import userdata\n",
        "from pyngrok import ngrok"
      ],
      "metadata": {
        "id": "UcKlEA_1j0cX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# URL de la carpeta compartida para el modelo y el diccionario\n",
        "folder_url_modelo = 'https://drive.google.com/drive/folders/1wQv6lTixINg17x9E2JNhWoDO1fi7l4Xx?usp=sharing'"
      ],
      "metadata": {
        "id": "MNGQ2JKYSE6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extraemos el ID de la carpeta del modelo y el diccionario\n",
        "folder_id_modelo = folder_url_modelo.split('/')[-1].split('?')[0]"
      ],
      "metadata": {
        "id": "909V8OdESHMZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Listamos los archivos en la carpeta usando gdown\n",
        "!gdown --folder {folder_id_modelo}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-5I9VD3SOr6",
        "outputId": "fa0159a8-b369-49c9-efa5-39ce375c5835"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieving folder contents\n",
            "Processing file 1w7blx-lYxGVdkmyL67LklXXs8tKj00Vt dict_model_results.pkl\n",
            "Processing file 1yuWQajrhukyKLHDkt0BeWajoNPF_djUY model_random_forest.pkl\n",
            "Retrieving folder contents completed\n",
            "Building directory structure\n",
            "Building directory structure completed\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1w7blx-lYxGVdkmyL67LklXXs8tKj00Vt\n",
            "To: /content/FraudDetection_Pipeline/dict_model_results.pkl\n",
            "100% 2.62k/2.62k [00:00<00:00, 12.8MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1yuWQajrhukyKLHDkt0BeWajoNPF_djUY\n",
            "To: /content/FraudDetection_Pipeline/model_random_forest.pkl\n",
            "100% 719k/719k [00:00<00:00, 13.8MB/s]\n",
            "Download completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dict_model_results = '/content/FraudDetection_Pipeline/dict_model_results.pkl'\n",
        "model_random_forest = '/content/FraudDetection_Pipeline/model_random_forest.pkl'"
      ],
      "metadata": {
        "id": "RYumZvAwSPm-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_randomforest = joblib.load(model_random_forest)\n",
        "results_pipeline = joblib.load(dict_model_results)"
      ],
      "metadata": {
        "id": "cx6XUH9Rj9_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar que el modelo y los resultados se ha cargado correctamente\n",
        "print(model_randomforest)\n",
        "print(results_pipeline)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOLlX3swl4rZ",
        "outputId": "e03a2a01-1701-4d55-c68d-d2e9d81a8bf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier(n_estimators=25)\n",
            "{'names': ['Random Forest', 'LASSO', 'KNN', 'Decision Tree', 'SVM', 'Gradient Boosting'], 'results': [array([0.99700832, 0.99648803, 0.99596774, 0.99687785, 0.99609731]), array([0.98907388, 0.98868366, 0.98725286, 0.98816183, 0.98660075]), array([0.98478148, 0.98426119, 0.9866025 , 0.98360869, 0.98503968]), array([0.99544745, 0.99544745, 0.99362643, 0.99440614, 0.99453623]), array([0.99063476, 0.99011446, 0.99037461, 0.98907246, 0.98868219]), array([0.99583767, 0.9951873 , 0.99440687, 0.99544686, 0.9949265 ])], 'models': [('Random Forest', RandomForestClassifier(random_state=42)), ('LASSO', LogisticRegression(random_state=42)), ('KNN', KNeighborsClassifier()), ('Decision Tree', DecisionTreeClassifier(random_state=42)), ('SVM', SVC(random_state=42)), ('Gradient Boosting', GradientBoostingClassifier(random_state=42))]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Empezamos a probar mlfflow y ngrok\n",
        "ngrok.kill()\n",
        "\n",
        "NGROK_AUTH_TOKEN = userdata.get('NGROK_AUTH_TOKEN')\n",
        "\n",
        "ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "\n",
        "ngrok_tunnel = ngrok.connect(addr='5000', proto='http', bind_tls=True)\n",
        "print('El tracking UI:', ngrok_tunnel.public_url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1WbnsQZERv5",
        "outputId": "18af8ed6-39e0-4ce0-c3a2-e993b1f8cd9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El tracking UI: https://3a52-35-186-188-202.ngrok-free.app\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Corremos todos los modelos utilizando el modelo y resultados guardados\n",
        "def best_model(results_pipeline):\n",
        "\n",
        "  # setemos en 0 los mejores resultados\n",
        "  best_mean_result = 0\n",
        "  best_std_result = 0\n",
        "\n",
        "  mlflow_ui_process = subprocess.Popen(['mlflow', 'ui', '--port', '5000'])\n",
        "\n",
        "  time.sleep(5)\n",
        "\n",
        "  mlflow.set_experiment(\"Script Eleccion Modelo\")\n",
        "\n",
        "  names = results_pipeline['names']\n",
        "  results = results_pipeline['results']\n",
        "  models = results_pipeline['models']\n",
        "\n",
        "  for i in range(len(results)):\n",
        "    with mlflow.start_run(run_name=results[i][0]) as run:\n",
        "      cv_results = results[i]\n",
        "      name = names[i]\n",
        "      model = models[i]\n",
        "      print(model)\n",
        "      mlflow.log_metric('m1', np.mean(cv_results))\n",
        "      mlflow.log_param('model', name)\n",
        "      mlflow.log_param('accuracy', cv_results)\n",
        "      mlflow.sklearn.log_model(model, 'clf_model')\n",
        "\n",
        "      names.append(name)\n",
        "      print(name + \": mean(accuracy)=\" + str(round(np.mean(cv_results), 3)) + \", std(accuracy)=\" + str(round(np.std(cv_results), 3)))\n",
        "\n",
        "      if (best_mean_result < np.mean(cv_results)) or \\\n",
        "        ((best_mean_result == np.mean(cv_results)) and (best_std_result > np.std(cv_results))):\n",
        "        best_mean_result = np.mean(cv_results)\n",
        "        best_std_result = np.std(cv_results)\n",
        "        best_model_name = name\n",
        "        best_model = model\n",
        "\n",
        "  return best_model, best_model_name"
      ],
      "metadata": {
        "id": "Gm8VMGN9EVQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# probamos la generaciÃ³n de resultados y login en mlflow\n",
        "\n",
        "best_model(results_pipeline)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wj5ii4Q0EZBi",
        "outputId": "032f65bd-a291-4b94-bdd7-77ce85024e19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/07/18 15:30:21 INFO mlflow.tracking.fluent: Experiment with name 'Script Eleccion Modelo' does not exist. Creating a new experiment.\n",
            "2024/07/18 15:30:21 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Random Forest', RandomForestClassifier(random_state=42))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
            "  warnings.warn(\"Setuptools is replacing distutils.\")\n",
            "2024/07/18 15:30:25 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest: mean(accuracy)=0.996, std(accuracy)=0.0\n",
            "('LASSO', LogisticRegression(random_state=42))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/07/18 15:30:27 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LASSO: mean(accuracy)=0.988, std(accuracy)=0.001\n",
            "('KNN', KNeighborsClassifier())\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/07/18 15:30:29 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN: mean(accuracy)=0.985, std(accuracy)=0.001\n",
            "('Decision Tree', DecisionTreeClassifier(random_state=42))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/07/18 15:30:31 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree: mean(accuracy)=0.995, std(accuracy)=0.001\n",
            "('SVM', SVC(random_state=42))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/07/18 15:30:33 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM: mean(accuracy)=0.99, std(accuracy)=0.001\n",
            "('Gradient Boosting', GradientBoostingClassifier(random_state=42))\n",
            "Gradient Boosting: mean(accuracy)=0.995, std(accuracy)=0.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(('Random Forest', RandomForestClassifier(random_state=42)), 'Random Forest')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    }
  ]
}